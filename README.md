# crantconnectome-haberkernlab-meshcreation

Mesh creation workflow for the Haberkern Lab for clonal raider ant connectome (CRANTb).

## Overview

This is a simple CLI workflow that uses [Igneous](https://github.com/seung-lab/igneous) mesh generation tasks in the backend. The idea is to use 3D TIFF images of meshes (generated in Thermo Fisher AMIRA) to generate neuropil meshes that can be visualized in [Neuroglancer](https://github.com/google/neuroglancer).

## Installation

```bash
uv sync
```

## Usage

```bash
python tiff_to_mesh.py --d <directory of your 3d tiff file> \
                       --out <your output directory> \
                       --res <resolution of your mesh> \
                       --translate <mesh translation in nm> \
                       --unsharded \
                       --setgit
```

**Flags:**

| Flag | Description | Default |
|------|-------------|---------|
| `--d` | Directory containing your 3D TIFF file (required) | - |
| `--out` | Output directory for meshes | Same as `--d` |
| `--res` | Output resolution in nm for aligned meshes (three integers) | `800 800 840` |
| `--translate` | Translation in nm applied to mesh vertices (x y z) | `-5400 -5400 -60` |
| `--unsharded` | Use [unsharded](https://github.com/google/neuroglancer/blob/master/src/datasource/precomputed/meshes.md#unsharded-storage-of-multi-resolution-mesh-manifest) mesh format (default is [sharded](https://github.com/google/neuroglancer/blob/master/src/datasource/precomputed/meshes.md#sharded-storage-of-multi-resolution-mesh-manifest)) | Sharded |
| `--setgit` | Initialize a git repo in output for Neuroglancer | Disabled |

### Example

```bash
python tiff_to_mesh.py --d ./my_segmentation \
                       --out ./meshes \
                       --res 800 800 840 \
                       --translate -5400 -5400 -60 \
                       --setgit
```

## Adding the Mesh to Neuroglancer

After running with `--setgit`, push the generated mesh to GitHub. Then add it to your Neuroglancer state:

1. Click the **+** button to add a new source
2. Paste the raw GitHub content URL pointing to your mesh directory:

```
https://raw.githubusercontent.com/<username>/<repo>/<commit>/mesh/|neuroglancer-precomputed:
```

![Neuroglancer Layers](readme_images/neuroglancer_layers.png)

3. Configure the source with the layer defaults (no extra transform needed anymore):

![Neuroglancer Source Config](readme_images/neuroglancer_source.png)

## Alignment

Mesh alignment is baked into the mesh metadata transform. By default, vertices are positioned using:

`vertex_nm = vertex_voxel * [800, 800, 840] + [-5400, -5400, -60]`

No manual transform is required in Neuroglancer or CloudVolume for the **mesh** layer.

Note: the segmentation volume overlay uses `voxel_offset = [0, 0, 0]` and does not carry the translation, so it will not be co-registered with the meshes. If you need the volume overlay to align as well, set a matching offset in Neuroglancer's layer source transform.

## Output Structure

The output follows the [Neuroglancer precomputed format](https://github.com/google/neuroglancer/blob/master/src/datasource/precomputed/README.md). The top-level `info` file describes the volume (data type, resolution, chunk layout), and the `mesh/` subdirectory contains multi-resolution Draco-compressed meshes generated by [Igneous](https://github.com/seung-lab/igneous).

```
output_volume/
├── info              # Precomputed volume metadata (JSON)
├── <scale_key>/      # Raw segmentation chunks
├── mesh/             # Generated meshes
│   ├── info          # Mesh metadata (JSON)
│   └── *.shard       # Sharded mesh files (or per-segment files if --unsharded)
└── .git/             # Git repo (if --setgit)
```
